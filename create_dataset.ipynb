{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3810jvsc74a57bd07e85ec9bf098c5427e45e2f632dcd4eeff803b007e1abd287d600879388709c1",
      "display_name": "Python 3.8.10 64-bit"
    },
    "metadata": {
      "interpreter": {
        "hash": "7e85ec9bf098c5427e45e2f632dcd4eeff803b007e1abd287d600879388709c1"
      }
    },
    "colab": {
      "name": "deepsig_slice_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK5P40TQv-TN"
      },
      "source": [
        "import h5py\n",
        "import os\n",
        "import numpy as np\n",
        "import signal_processing as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import sklearn\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from fastprogress.fastprogress import progress_bar\n",
        "from sys import getsizeof"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AiCdQ0Gee66"
      },
      "source": [
        "# Get location of DEEPSIG DATASET: RADIOML 2018.01A dataset\n",
        "current_working_directory = os.getcwd()\n",
        "file_name = os.path.join(current_working_directory, \"DeepSig-Dataset-2018/GOLD_XYZ_OSC.0001_1024.hdf5\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm5IvdFgv-TP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efcf0cb6-dfb9-4600-9f10-bf23e495b51f"
      },
      "source": [
        "# Load File\n",
        "start = time.time()\n",
        "print(\"Loading dataset...\")\n",
        "f = h5py.File(file_name, 'r')\n",
        "\n",
        "# Get the dataset from each key \n",
        "x = f[\"X\"] # Dataset\n",
        "y = f[\"Y\"] # Labels\n",
        "z = f[\"Z\"] # SNR Value\n",
        "\n",
        "print(f\"Dataset loaded in {time.time() - start:.6f} seconds.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\nDataset loaded in 0.001320 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9bBXDAOv-TQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "c40ac437-81d8-46f6-baf7-0138ea38ff8a"
      },
      "source": [
        "# It is significantly faster to reshape an array than to concatenate multiple arrays. \n",
        "# Start be creating an empty array of a known size, where the first axis is the slices of the dataset we are keeping\n",
        "# Then reassign the elements of this empty array to be the slices of the larger array\n",
        "# Finally, reshape the array to the final shape\n",
        "\n",
        "num_samples_per_modulation_type = 106496\n",
        "start_of_snr_slice = snrindex[0][0]\n",
        "num_of_samples_with_desired_snr = num_samples_per_modulation_type - start_of_snr_slice\n",
        "\n",
        "# Use np.where to find indices where SNR is greater than the desired value.\n",
        "print(\"Slicing dataset with SNR >= 10\")\n",
        "snrindex = np.where(np.array(z) >= 10)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# For our dataset, x, we want to pick out the data where the SNR is greater than or equal to a certain SNR\n",
        "# The datatype of the X dataset is float32. This is important.\n",
        "# While the original datatype of Y is int64, use int16 to save a tiny bit of memory.\n",
        "dataset_slices = np.empty((24, num_of_samples_with_desired_snr, 1024, 2), dtype=np.float32)\n",
        "labels_slices = np.empty((24, num_of_samples_with_desired_snr, 24), dtype = np.int16)\n",
        "\n",
        "# We can then iterate over each of the modulation types\n",
        "# The numbers used in these are specifically chosen to pick out only SNR >= 0 values. \n",
        "for i in progress_bar(range(24)):\n",
        "    start = start_of_snr_slice + num_samples_per_modulation_type*i\n",
        "    end = 106496 + num_samples_per_modulation_type*i\n",
        "    dataset_slices[i] = np.array(x[start:end])\n",
        "    labels_slices[i] = np.array(y[start:end])\n",
        "\n",
        "# We can then reshape this array to the final shape, which is signfically faster than concatenation\n",
        "dataset = np.reshape(dataset_slices, (-1, 1024, 2))\n",
        "labels = np.reshape(labels_slices, (-1, 24))\n",
        "\n",
        "# Remove slices from memory\n",
        "del dataset_slices\n",
        "del labels_slices\n",
        "\n",
        "print(f\"Datasets created in {time.time() - start_time:.6f} seconds.\")\n",
        "\n",
        "# For fun, I timed the process of this method versus the old method using concatenation, and it is about 3 times faster. Plus, we get to see the progress, whereas concatenation just runs with no progress indicators. Reshaping is nearly instant. "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slicing dataset with SNR >= 10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='24' class='' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [24/24 00:25<00:00]\n    </div>\n    "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOLPOBSVv-TR"
      },
      "source": [
        "# The next step is to convert our dataset to complex values.\n",
        "# We can use our empty dataset method to speed things up to avoid concatenation\n",
        "print(\"Converting dataset to complex values...\")\n",
        "start = time.time()\n",
        "\n",
        "dataset_complex = np.empty((len(dataset), 1024), dtype = np.complex64)\n",
        "for i in progress_bar(range(len(dataset))):\n",
        "    # Flatten the dataset, to be in I/Q format that our signal_to_complex function expects\n",
        "    dataset_complex[i] = sp.signal_to_complex(np.reshape(dataset[i], (-1, )))\n",
        "\n",
        "print(f\"Converted dataset to complex values in {time.time() - start:.6f} seconds.\")\n",
        "\n",
        "# We can then remove the original dataset from memory to save precious memory\n",
        "del dataset"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting dataset to complex values...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='1572864' class='' max='1572864' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [1572864/1572864 01:21<00:00]\n    </div>\n    "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIuyA6gbv-TS"
      },
      "source": [
        "# Now we need to take a FFT of the complex dataset\n",
        "print(\"Calculating FFT of dataset...\")\n",
        "start = time.time()\n",
        "\n",
        "fft_dataset = np.empty((len(dataset_complex), 1024), dtype = np.float64)\n",
        "for i in progress_bar(range(len(dataset_complex))):\n",
        "    fft_dataset[i] = sp.fft_signal(dataset_complex[i])\n",
        "\n",
        "print(f\"Completed FFT calculaations in {time.time() - start:.6f} seconds.\")\n",
        "\n",
        "# Remove the complex dataset from memory\n",
        "del dataset_complex"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating FFT of dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='1572864' class='' max='1572864' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [1572864/1572864 03:25<00:00]\n    </div>\n    "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsQh5y8cv-TT"
      },
      "source": [
        "# Randomly shuffle dataset\n",
        "shuffler = np.random.permutation(len(labels))\n",
        "fft_dataset_shuffled = np.empty(shape = np.shape(fft_dataset), dtype = fft_dataset.dtype)\n",
        "labels_shuffled = np.empty(shape = np.shape(labels), dtype = labels.dtype)\n",
        "for i, j in enumerate(progress_bar(shuffler)):\n",
        "    fft_dataset_shuffled[i] = fft_dataset[j]\n",
        "    labels_shuffled[i] = labels[j]\n",
        "\n",
        "del fft_dataset\n",
        "del labels"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='1572864' class='' max='1572864' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [1572864/1572864 08:54<00:00]\n    </div>\n    "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'fft_dataset_shuffled' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-92962d568bee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mlabels_shuffled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"train contains {len(fft_dataset_train)/len(fft_dataset_shuffled) * 100:.2f}% of the total dataset.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"val contains {len(fft_dataset_val)/len(fft_dataset_shuffled) * 100:.2f}% of the total dataset.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"test contains {len(fft_dataset_test)/len(fft_dataset_shuffled) * 100:.2f}% of the total dataset.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fft_dataset_shuffled' is not defined"
          ]
        }
      ],
      "source": [
        "# Split dataset into train, validation, and test sets\n",
        "# 1572864 elements total\n",
        "# Use about 50% for training, 20% for val, 30% for test\n",
        "# [:800_000]\n",
        "# [800_000:1_100_000]\n",
        "# [1_100_000:]\n",
        "\n",
        "fft_dataset_train = fft_dataset_shuffled[:800_000]\n",
        "fft_dataset_val = fft_dataset_shuffled[800_000:1_100_000]\n",
        "fft_dataset_test = fft_dataset_shuffled[1_100_000:]\n",
        "\n",
        "labels_train = labels_shuffled[:800_000]\n",
        "labels_val = labels_shuffled[800_000:1_100_000]\n",
        "labels_test = labels_shuffled[1_100_000:]\n",
        "\n",
        "print(f\"train contains {len(fft_dataset_train)/len(fft_dataset_shuffled) * 100:.2f}% of the total dataset.\")\n",
        "print(f\"val contains {len(fft_dataset_val)/len(fft_dataset_shuffled) * 100:.2f}% of the total dataset.\")\n",
        "print(f\"test contains {len(fft_dataset_test)/len(fft_dataset_shuffled) * 100:.2f}% of the total dataset.\")\n",
        "\n",
        "del fft_dataset_shuffled\n",
        "del labels_shuffled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6QgxTFVwBO0"
      },
      "source": [
        "# Save shuffled FFT datasets\n",
        "save_path = os.path.join(current_working_directory, \"DeepSig-Dataset-2018/\")\n",
        "np.save(os.path.join(save_path, \"fft_dataset_train.npy\"), fft_dataset_train)\n",
        "np.save(os.path.join(save_path, \"fft_dataset_val.npy\"), fft_dataset_val)\n",
        "np.save(os.path.join(save_path, \"fft_dataset_test.npy\"), fft_dataset_test)\n",
        "\n",
        "np.save(os.path.join(save_path, \"labels_train.npy\"), labels_train)\n",
        "np.save(os.path.join(save_path, \"labels_val.npy\"), labels_val)\n",
        "np.save(os.path.join(save_path, \"labels_test.npy\"), labels_test)\n",
        "\n",
        "print(\"Successfully saved all datasets.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved all datasets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}
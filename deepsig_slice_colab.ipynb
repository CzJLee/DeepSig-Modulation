{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3810jvsc74a57bd07e85ec9bf098c5427e45e2f632dcd4eeff803b007e1abd287d600879388709c1",
      "display_name": "Python 3.8.10 64-bit"
    },
    "metadata": {
      "interpreter": {
        "hash": "7e85ec9bf098c5427e45e2f632dcd4eeff803b007e1abd287d600879388709c1"
      }
    },
    "colab": {
      "name": "deepsig_slice_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CzJLee/DeepSig-Modulation/blob/master/deepsig_slice_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TG_l8gvwCj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2ca1640-bba9-45a7-efe8-36d82765b2f8"
      },
      "source": [
        "!git clone https://github.com/CzJLee/DeepSig-Modulation\n",
        "!cp DeepSig-Modulation/signal_processing.py signal_processing.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepSig-Modulation'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 49 (delta 17), reused 42 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK5P40TQv-TN"
      },
      "source": [
        "import h5py\n",
        "import os\n",
        "import numpy as np\n",
        "import signal_processing as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import sklearn\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from fastprogress.fastprogress import progress_bar\n",
        "from sys import getsizeof"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu6fS9lnwkdD",
        "outputId": "45271832-f7fc-4163-976f-96bbb78dbddc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AiCdQ0Gee66"
      },
      "source": [
        "# Get location of DEEPSIG DATASET: RADIOML 2018.01A dataset\n",
        "current_working_directory = os.getcwd()\n",
        "file_name = os.path.join(current_working_directory, \"drive/MyDrive/DeepSig-Dataset-2018/GOLD_XYZ_OSC.0001_1024.hdf5\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm5IvdFgv-TP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bec6760-c1f2-4b3c-96fc-fb14b212ced5"
      },
      "source": [
        "# Load File\n",
        "start = time.time()\n",
        "print(\"Loading dataset...\")\n",
        "f = h5py.File(file_name, 'r')\n",
        "\n",
        "# Get the dataset from each key \n",
        "x = f[\"X\"] # Dataset\n",
        "y = f[\"Y\"] # Labels\n",
        "z = f[\"Z\"] # SNR Value\n",
        "\n",
        "print(f\"Dataset loaded in {time.time() - start:.6f} seconds.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "Dataset loaded in 0.396137 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9bBXDAOv-TQ",
        "outputId": "e76cc8c9-e979-4187-d183-88eabbcc4b79"
      },
      "source": [
        "# It is significantly faster to reshape an array than to concatenate multiple arrays. \n",
        "# Start be creating an empty array of a known size, where the first axis is the slices of the dataset we are keeping\n",
        "# Then reassign the elements of this empty array to be the slices of the larger array\n",
        "# Finally, reshape the array to the final shape\n",
        "\n",
        "print(\"Slicing dataset with SNR >= 0\")\n",
        "start = time.time()\n",
        "\n",
        "# For our dataset, x, we want to pick out the data where the SNR is greater than or equal to zero\n",
        "# There are 65,536 such samples for each of the 24 modulation types\n",
        "# The datatype of the X dataset is float32. This is important.\n",
        "# While the original datatype of Y is int64, use int16 to save a tiny bit of memory.\n",
        "dataset_slices = np.empty((24, 65536, 1024, 2), dtype=np.float32)\n",
        "labels_slices = np.empty((24, 65536, 24), dtype = np.int16)\n",
        "\n",
        "# We can then iterate over each of the modulation types\n",
        "# The numbers used in these are specifically chosen to pick out only SNR >= 0 values. \n",
        "for i in progress_bar(range(24)):\n",
        "    n = 106496\n",
        "    start = 40960+n*i\n",
        "    end = 106496+n*i\n",
        "    dataset_slices[i] = x[start:end]\n",
        "    labels_slices[i] = y[start:end]\n",
        "\n",
        "# We can then reshape this array to the final shape, which is signfically faster than concatenation\n",
        "dataset = np.reshape(dataset_slices, (1572864, 1024, 2))\n",
        "labels = np.reshape(labels_slices, (1572864, 24))\n",
        "\n",
        "# Remove slices from memory\n",
        "del dataset_slices\n",
        "del labels_slices\n",
        "\n",
        "print(f\"Datasets created in {time.time() - start:.6f} seconds.\")\n",
        "\n",
        "# For fun, I timed the process of this method versus the old method using concatenation, and it is about 3 times faster. Plus, we get to see the progress, whereas concatenation just runs with no progress indicators. Reshaping is nearly instant. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Slicing dataset with SNR >= 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='24' class='' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [24/24 00:19<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOLPOBSVv-TR",
        "outputId": "dde6c412-1e6d-4e07-8399-383de06ff4ea"
      },
      "source": [
        "# The next step is to convert our dataset to complex values.\n",
        "# We can use our empty dataset method to speed things up to avoid concatenation\n",
        "print(\"Converting dataset to complex values...\")\n",
        "start = time.time()\n",
        "\n",
        "dataset_complex = np.empty((len(dataset), 1024), dtype = np.complex64)\n",
        "for i in progress_bar(range(len(dataset))):\n",
        "    # Flatten the dataset, to be in I/Q format that our signal_to_complex function expects\n",
        "    dataset_complex[i] = sp.signal_to_complex(np.reshape(dataset[i], (-1, )))\n",
        "\n",
        "print(f\"Converted dataset to complex values in {time.time() - start:.6f} seconds.\")\n",
        "\n",
        "# We can then remove the original dataset from memory to save precious memory\n",
        "del dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting dataset to complex values...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1572864' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      \n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Converted dataset to complex values in 71.715005 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIuyA6gbv-TS",
        "outputId": "38c92251-8b32-4e28-bf07-b5bd0394c22b"
      },
      "source": [
        "# Now we need to take a FFT of the complex dataset\n",
        "print(\"Calculating FFT of dataset...\")\n",
        "start = time.time()\n",
        "\n",
        "fft_dataset = np.empty((len(dataset_complex), 1024), dtype = np.float64)\n",
        "for i in progress_bar(range(len(dataset_complex))):\n",
        "    fft_dataset[i] = sp.fft_signal(dataset_complex[i])\n",
        "\n",
        "print(f\"Completed FFT calculaations in {time.time() - start:.6f} seconds.\")\n",
        "\n",
        "# Remove the complex dataset from memory\n",
        "del dataset_complex"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating FFT of dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1572864' class='' max='1572864' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [1572864/1572864 03:25<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsQh5y8cv-TT",
        "outputId": "2abd0fbb-95f4-4cac-d925-f390f1c8fc4b"
      },
      "source": [
        "# Randomly shuffle dataset\n",
        "shuffler = np.random.permutation(len(labels))\n",
        "fft_dataset_shuffled = np.empty(shape = np.shape(fft_dataset), dtype = fft_dataset.dtype)\n",
        "for i, j in enumerate(progress_bar(shuffler)):\n",
        "    fft_dataset_shuffled[i] = fft_dataset[j]\n",
        "    labels_shuffled[i] = labels[j]\n",
        "\n",
        "del fft_dataset\n",
        "del labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1199007,  656258, 1036552, ...,  795744, 1376078, 1142829])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6QgxTFVwBO0"
      },
      "source": [
        "# Save shuffled FFT datasets\n",
        "save_path = os.path.join(current_working_directory, \"drive/MyDrive/DeepSig-Dataset-2018/\")\n",
        "np.save(os.path.join(save_path, \"fft_dataset_shuffled.npy\"), fft_dataset_shuffled)\n",
        "np.save(os.path.join(save_path, \"labels_shuffled.npy\"), labels_shuffled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxu0FtRwfpHP"
      },
      "source": [
        "# Build CNN Model following DeepSig model\n",
        "\n",
        "inputs = keras.Input(shape=(1024, 1))\n",
        "x = layers.Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
        "x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "x = layers.Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n",
        "x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "x = layers.Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n",
        "x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "x = layers.Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n",
        "x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "x = layers.Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n",
        "x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "x = layers.Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n",
        "x = layers.MaxPooling1D(pool_size=2)(x)\n",
        "x = layers.Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(128)(x)\n",
        "x = layers.Dense(128)(x)\n",
        "outputs = layers.Dense(24, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZNtoP9QgTJ9",
        "outputId": "21ba5960-fadb-48ea-eca8-769eb9c3241d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 1024, 1)]         0         \n",
            "_________________________________________________________________\n",
            "conv1d_42 (Conv1D)           (None, 1022, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_35 (MaxPooling (None, 511, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_43 (Conv1D)           (None, 509, 64)           12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_36 (MaxPooling (None, 254, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_44 (Conv1D)           (None, 252, 64)           12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_37 (MaxPooling (None, 126, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_45 (Conv1D)           (None, 124, 64)           12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_38 (MaxPooling (None, 62, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_46 (Conv1D)           (None, 60, 64)            12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_39 (MaxPooling (None, 30, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_47 (Conv1D)           (None, 28, 64)            12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_40 (MaxPooling (None, 14, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_48 (Conv1D)           (None, 12, 64)            12352     \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 768)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 128)               98432     \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 24)                3096      \n",
            "=================================================================\n",
            "Total params: 192,408\n",
            "Trainable params: 192,408\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8-goCWBgt7q"
      },
      "source": [
        " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Define the callbacks and save the best model to a new file\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\n",
        "    filepath='models/cnn_test.keras',\n",
        "    save_best_only=True,\n",
        "    monitor='val_loss')]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmkwBNb2hGds"
      },
      "source": [
        "# Time the time it takes to train the model\n",
        "start = time.time()\n",
        "\n",
        "history = model.fit(fft_dataset_shuffled, labels_shuffled, epochs=1, batch_size = 256, validation_split = 0.3, callbacks=callbacks)\n",
        "\n",
        "print(\"--- Model trained in %s seconds ---\" % (time.time() - start))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
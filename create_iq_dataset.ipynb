{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3810jvsc74a57bd07e85ec9bf098c5427e45e2f632dcd4eeff803b007e1abd287d600879388709c1",
      "display_name": "Python 3.8.10 64-bit"
    },
    "metadata": {
      "interpreter": {
        "hash": "7e85ec9bf098c5427e45e2f632dcd4eeff803b007e1abd287d600879388709c1"
      }
    },
    "colab": {
      "name": "deepsig_slice_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK5P40TQv-TN"
      },
      "source": [
        "import h5py\n",
        "import os\n",
        "import numpy as np\n",
        "import signal_processing as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import sklearn\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from fastprogress.fastprogress import progress_bar\n",
        "from sys import getsizeof"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AiCdQ0Gee66"
      },
      "source": [
        "# Get location of DEEPSIG DATASET: RADIOML 2018.01A dataset\n",
        "current_working_directory = os.getcwd()\n",
        "file_name = os.path.join(current_working_directory, \"DeepSig-Dataset-2018/GOLD_XYZ_OSC.0001_1024.hdf5\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm5IvdFgv-TP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efcf0cb6-dfb9-4600-9f10-bf23e495b51f"
      },
      "source": [
        "# Load File\n",
        "start = time.time()\n",
        "print(\"Loading dataset...\")\n",
        "f = h5py.File(file_name, 'r')\n",
        "\n",
        "# Get the dataset from each key \n",
        "x = f[\"X\"] # Dataset\n",
        "y = f[\"Y\"] # Labels\n",
        "z = f[\"Z\"] # SNR Value\n",
        "\n",
        "print(f\"Dataset loaded in {time.time() - start:.6f} seconds.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\nDataset loaded in 0.004881 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9bBXDAOv-TQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "c40ac437-81d8-46f6-baf7-0138ea38ff8a"
      },
      "source": [
        "# It is significantly faster to reshape an array than to concatenate multiple arrays. \n",
        "# Start be creating an empty array of a known size, where the first axis is the slices of the dataset we are keeping\n",
        "# Then reassign the elements of this empty array to be the slices of the larger array\n",
        "# Finally, reshape the array to the final shape\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Use np.where to find indices where SNR is greater than the desired value.\n",
        "print(\"Slicing dataset with SNR >= 10\")\n",
        "snrindex = np.where(np.array(z) >= 10)\n",
        "num_samples_per_modulation_type = 106496\n",
        "\n",
        "start_of_snr_slice = snrindex[0][0]\n",
        "num_of_samples_with_desired_snr = num_samples_per_modulation_type - start_of_snr_slice\n",
        "\n",
        "# For our dataset, x, we want to pick out the data where the SNR is greater than or equal to a certain SNR\n",
        "# The datatype of the X dataset is float32. This is important.\n",
        "# While the original datatype of Y is int64, use int16 to save a tiny bit of memory.\n",
        "dataset_slices = np.empty((24, num_of_samples_with_desired_snr, 1024, 2), dtype=np.float32)\n",
        "labels_slices = np.empty((24, num_of_samples_with_desired_snr, 24), dtype = np.int16)\n",
        "\n",
        "# We can then iterate over each of the modulation types\n",
        "# The numbers used in these are specifically chosen to pick out only SNR >= 0 values. \n",
        "for i in progress_bar(range(24)):\n",
        "    start = start_of_snr_slice + num_samples_per_modulation_type*i\n",
        "    end = 106496 + num_samples_per_modulation_type*i\n",
        "    dataset_slices[i] = np.array(x[start:end])\n",
        "    labels_slices[i] = np.array(y[start:end])\n",
        "\n",
        "# We can then reshape this array to the final shape, which is signfically faster than concatenation\n",
        "dataset = np.reshape(dataset_slices, (-1, 1024, 2))\n",
        "labels = np.reshape(labels_slices, (-1, 24))\n",
        "\n",
        "# Remove slices from memory\n",
        "del dataset_slices\n",
        "del labels_slices\n",
        "\n",
        "print(f\"Datasets created in {time.time() - start_time:.6f} seconds.\")\n",
        "\n",
        "# For fun, I timed the process of this method versus the old method using concatenation, and it is about 3 times faster. Plus, we get to see the progress, whereas concatenation just runs with no progress indicators. Reshaping is nearly instant. "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slicing dataset with SNR >= 10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='24' class='' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [24/24 00:24<00:00]\n    </div>\n    "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsQh5y8cv-TT"
      },
      "source": [
        "# Randomly shuffle dataset\n",
        "shuffler = np.random.permutation(len(labels))\n",
        "dataset_shuffled = np.empty(shape = np.shape(fft_dataset), dtype = dataset.dtype)\n",
        "labels_shuffled = np.empty(shape = np.shape(labels), dtype = labels.dtype)\n",
        "for i, j in enumerate(progress_bar(shuffler)):\n",
        "    dataset_shuffled[i] = dataset[j]\n",
        "    labels_shuffled[i] = labels[j]\n",
        "\n",
        "del dataset\n",
        "del labels"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='1081344' class='' max='1081344' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [1081344/1081344 02:18<00:00]\n    </div>\n    "
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train contains 50.00% of the total dataset.\nval contains 20.00% of the total dataset.\ntest contains 30.00% of the total dataset.\n"
          ]
        }
      ],
      "source": [
        "# Split dataset into train, validation, and test sets\n",
        "# Use about 50% for training, 20% for val, 30% for test\n",
        "\n",
        "total_num_elements = len(labels_shuffled)\n",
        "\n",
        "dataset_train = dataset_shuffled[:int(0.5 * total_num_elements)]\n",
        "dataset_val = dataset_shuffled[int(0.5 * total_num_elements):int(0.7 * total_num_elements)]\n",
        "dataset_test = dataset_shuffled[int(0.7 * total_num_elements):]\n",
        "\n",
        "labels_train = labels_shuffled[:int(0.5 * total_num_elements)]\n",
        "labels_val = labels_shuffled[int(0.5 * total_num_elements):int(0.7 * total_num_elements)]\n",
        "labels_test = labels_shuffled[int(0.7 * total_num_elements):]\n",
        "\n",
        "print(f\"train contains {len(labels_train)} elements.\")\n",
        "print(f\"val contains {len(labels_val)} elements\")\n",
        "print(f\"test contains {len(labels_val)} elements\")\n",
        "\n",
        "del dataset_shuffled\n",
        "del labels_shuffled"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6QgxTFVwBO0"
      },
      "source": [
        "# Save shuffled datasets\n",
        "save_path = os.path.join(current_working_directory, \"DeepSig-Dataset-2018/\")\n",
        "np.save(os.path.join(save_path, \"iq_dataset_train.npy\"), dataset_train)\n",
        "np.save(os.path.join(save_path, \"iq_dataset_val.npy\"), dataset_val)\n",
        "np.save(os.path.join(save_path, \"iq_dataset_test.npy\"), dataset_test)\n",
        "\n",
        "np.save(os.path.join(save_path, \"iq_labels_train.npy\"), labels_train)\n",
        "np.save(os.path.join(save_path, \"iq_labels_val.npy\"), labels_val)\n",
        "np.save(os.path.join(save_path, \"iq_labels_test.npy\"), labels_test)\n",
        "\n",
        "print(\"Successfully saved all datasets.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved all datasets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Train dataset has size {getsizeof(dataset_train)} bytes.\")\n",
        "print(f\"Validation dataset has size {getsizeof(dataset_val)} bytes.\")\n",
        "print(f\"Test dataset has size {getsizeof(dataset_test)} bytes.\")\n"
      ]
    }
  ]
}
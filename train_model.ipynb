{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd07e85ec9bf098c5427e45e2f632dcd4eeff803b007e1abd287d600879388709c1",
   "display_name": "Python 3.8.10 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "7e85ec9bf098c5427e45e2f632dcd4eeff803b007e1abd287d600879388709c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import signal_processing as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "dataset_directory = os.path.join(os.getcwd(), \"DeepSig-Dataset-2018\")\n",
    "\n",
    "# Use these to load the entire dataset into memory\n",
    "fft_dataset_train = np.load(os.path.join(dataset_directory, \"fft_dataset_train.npy\"))\n",
    "fft_dataset_val = np.load(os.path.join(dataset_directory, \"fft_dataset_val.npy\"))\n",
    "fft_dataset_test = np.load(os.path.join(dataset_directory, \"fft_dataset_test.npy\"))\n",
    "\n",
    "labels_train = np.load(os.path.join(dataset_directory, \"labels_train.npy\"))\n",
    "labels_val = np.load(os.path.join(dataset_directory, \"labels_val.npy\"))\n",
    "labels_test = np.load(os.path.join(dataset_directory, \"labels_test.npy\"))\n",
    "\n",
    "# # Use these to use a memory map to save RAM\n",
    "# fft_dataset_train = np.load(os.path.join(dataset_directory, \"fft_dataset_train.npy\"), mmap_mode=\"r+\")\n",
    "# fft_dataset_val = np.load(os.path.join(dataset_directory, \"fft_dataset_val.npy\"), mmap_mode=\"r+\")\n",
    "# fft_dataset_test = np.load(os.path.join(dataset_directory, \"fft_dataset_test.npy\"), mmap_mode=\"r+\")\n",
    "\n",
    "# labels_train = np.load(os.path.join(dataset_directory, \"labels_train.npy\"), mmap_mode=\"r+\")\n",
    "# labels_val = np.load(os.path.join(dataset_directory, \"labels_val.npy\"), mmap_mode=\"r+\")\n",
    "# labels_test = np.load(os.path.join(dataset_directory, \"labels_test.npy\"), mmap_mode=\"r+\")"
   ]
  },
  {
   "source": [
    "Super crude hyper parameter tuning by creating multiple different models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of models\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Model\n",
    "inputs = keras.Input(shape=(1024, 1))\n",
    "x = layers.Conv1D(filters=16, kernel_size=3, activation='relu')(inputs)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=32, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128)(x)\n",
    "x = layers.Dense(128)(x)\n",
    "outputs = layers.Dense(24, activation='softmax')(x)\n",
    "\n",
    "models.append(keras.Model(inputs=inputs, outputs=outputs, name = \"base_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small Model\n",
    "inputs = keras.Input(shape=(1024, 1))\n",
    "x = layers.Conv1D(filters=16, kernel_size=3, activation='relu')(inputs)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=32, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128)(x)\n",
    "x = layers.Dense(128)(x)\n",
    "outputs = layers.Dense(24, activation='softmax')(x)\n",
    "\n",
    "models.append(keras.Model(inputs=inputs, outputs=outputs, name = \"small_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Less Dense Layers\n",
    "inputs = keras.Input(shape=(1024, 1))\n",
    "x = layers.Conv1D(filters=16, kernel_size=3, activation='relu')(inputs)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=32, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128)(x)\n",
    "outputs = layers.Dense(24, activation='softmax')(x)\n",
    "\n",
    "models.append(keras.Model(inputs=inputs, outputs=outputs, name = \"less_dense\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch normalization\n",
    "inputs = keras.Input(shape=(1024, 1))\n",
    "x = layers.Conv1D(filters=16, kernel_size=3, activation='relu')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=32, kernel_size=3, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128)(x)\n",
    "x = layers.Dense(128)(x)\n",
    "outputs = layers.Dense(24, activation='softmax')(x)\n",
    "\n",
    "models.append(keras.Model(inputs=inputs, outputs=outputs, name = \"batch_normalization\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double Conv Layers\n",
    "inputs = keras.Input(shape=(1024, 1))\n",
    "x = layers.Conv1D(filters=16, kernel_size=3, activation='relu')(inputs)\n",
    "x = layers.Conv1D(filters=16, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=32, kernel_size=3, activation='relu')(x)\n",
    "x = layers.Conv1D(filters=32, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "x = layers.Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = layers.Conv1D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128)(x)\n",
    "x = layers.Dense(128)(x)\n",
    "outputs = layers.Dense(24, activation='softmax')(x)\n",
    "\n",
    "models.append(keras.Model(inputs=inputs, outputs=outputs, name = \"double_conv_layers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of optimizers to use\n",
    "optimizers = [\"adam\", \"sgd\", \"rmsprop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "fft_dataset_train = fft_dataset_train[:100]\n",
    "fft_dataset_val = fft_dataset_val[:100]\n",
    "fft_dataset_test = fft_dataset_test[:100]\n",
    "\n",
    "labels_train = labels_train[:100]\n",
    "labels_val = labels_val[:100]\n",
    "labels_test = labels_test[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.7699 - accuracy: 0.0600 - val_loss: 5.5929 - val_accuracy: 0.0200\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 5.7461 - accuracy: 0.0500 - val_loss: 4.4640 - val_accuracy: 0.0500\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 4.6950 - accuracy: 0.0600 - val_loss: 3.3205 - val_accuracy: 0.0500\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 3.3984 - accuracy: 0.0600 - val_loss: 3.2574 - val_accuracy: 0.0100\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 3.1771 - accuracy: 0.0400 - val_loss: 3.3193 - val_accuracy: 0.0300\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 3.1429 - accuracy: 0.0500 - val_loss: 3.3000 - val_accuracy: 0.0500\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 3.0905 - accuracy: 0.0700 - val_loss: 3.3266 - val_accuracy: 0.0500\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 3.0801 - accuracy: 0.0800 - val_loss: 3.3592 - val_accuracy: 0.0400\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 3.0638 - accuracy: 0.0700 - val_loss: 3.3946 - val_accuracy: 0.0400\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2211 - accuracy: 0.0700\n",
      "--- Model trained in 3.6469130516052246 seconds ---\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.4181 - accuracy: 0.0800 - val_loss: 27.4426 - val_accuracy: 0.0500\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 23.4994 - accuracy: 0.0600 - val_loss: 20.3319 - val_accuracy: 0.0200\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 18.2834 - accuracy: 0.0600 - val_loss: 10.7097 - val_accuracy: 0.0300\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 10.5887 - accuracy: 0.0200 - val_loss: 5.6483 - val_accuracy: 0.0600\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 5.9369 - accuracy: 0.0300 - val_loss: 4.0381 - val_accuracy: 0.0500\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 4.1978 - accuracy: 0.0700 - val_loss: 3.6793 - val_accuracy: 0.0500\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 3.6397 - accuracy: 0.0700 - val_loss: 3.4515 - val_accuracy: 0.0600\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 3.2097 - accuracy: 0.0900 - val_loss: 3.6628 - val_accuracy: 0.0500\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 3.2613 - accuracy: 0.0600 - val_loss: 3.4214 - val_accuracy: 0.0700\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 3.0847 - accuracy: 0.0600 - val_loss: 3.3783 - val_accuracy: 0.0500\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 3.0893 - accuracy: 0.0700 - val_loss: 3.3492 - val_accuracy: 0.0400\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 3.0604 - accuracy: 0.0900 - val_loss: 3.3113 - val_accuracy: 0.0400\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 3.0155 - accuracy: 0.0700 - val_loss: 3.3190 - val_accuracy: 0.0800\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 2.9926 - accuracy: 0.1300 - val_loss: 3.3306 - val_accuracy: 0.0800\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 2.9638 - accuracy: 0.1600 - val_loss: 3.3493 - val_accuracy: 0.0900\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 2.9315 - accuracy: 0.1800 - val_loss: 3.3969 - val_accuracy: 0.0800\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 2.9047 - accuracy: 0.1600 - val_loss: 3.4283 - val_accuracy: 0.0900\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2511 - accuracy: 0.0400\n",
      "--- Model trained in 4.533030033111572 seconds ---\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 887ms/step - loss: 5.6869 - accuracy: 0.0100 - val_loss: 6.8741 - val_accuracy: 0.0200\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 5.9183 - accuracy: 0.0500 - val_loss: 6.9735 - val_accuracy: 0.0100\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 6.3968 - accuracy: 0.0400 - val_loss: 4.6888 - val_accuracy: 0.0400\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 4.5113 - accuracy: 0.0700 - val_loss: 4.0222 - val_accuracy: 0.0400\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 3.9785 - accuracy: 0.0700 - val_loss: 3.6935 - val_accuracy: 0.0500\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 3.6423 - accuracy: 0.0700 - val_loss: 3.4875 - val_accuracy: 0.0500\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 3.3569 - accuracy: 0.0600 - val_loss: 3.4078 - val_accuracy: 0.0300\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 3.1748 - accuracy: 0.0700 - val_loss: 3.3862 - val_accuracy: 0.0100\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 3.1038 - accuracy: 0.0500 - val_loss: 3.3722 - val_accuracy: 0.0500\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 3.0712 - accuracy: 0.0900 - val_loss: 3.4098 - val_accuracy: 0.0400\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 3.0600 - accuracy: 0.0700 - val_loss: 3.4476 - val_accuracy: 0.0400\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 3.0515 - accuracy: 0.0900 - val_loss: 3.4377 - val_accuracy: 0.0600\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 3.0391 - accuracy: 0.0900 - val_loss: 3.3910 - val_accuracy: 0.0900\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 3.0273 - accuracy: 0.1200 - val_loss: 3.3537 - val_accuracy: 0.0500\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 3.0212 - accuracy: 0.0900 - val_loss: 3.3456 - val_accuracy: 0.0400\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 3.0148 - accuracy: 0.0700 - val_loss: 3.3557 - val_accuracy: 0.0500\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 3.0034 - accuracy: 0.0900 - val_loss: 3.3779 - val_accuracy: 0.0800\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 2.9888 - accuracy: 0.1100 - val_loss: 3.4089 - val_accuracy: 0.0800\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 2.9725 - accuracy: 0.1100 - val_loss: 3.4413 - val_accuracy: 0.0700\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.3213 - accuracy: 0.0400\n",
      "--- Model trained in 4.576091051101685 seconds ---\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.2714 - accuracy: 0.0800 - val_loss: 3.5872 - val_accuracy: 0.0500\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.4981 - accuracy: 0.6300 - val_loss: 3.5744 - val_accuracy: 0.0500\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.7537 - accuracy: 0.8200 - val_loss: 3.7376 - val_accuracy: 0.0500\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.6150 - accuracy: 0.8100 - val_loss: 3.8535 - val_accuracy: 0.0600\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2807 - accuracy: 0.9600 - val_loss: 3.8685 - val_accuracy: 0.0500\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 307ms/step - loss: 0.2122 - accuracy: 0.9700 - val_loss: 3.8102 - val_accuracy: 0.0700\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.1939 - accuracy: 0.9800 - val_loss: 3.7170 - val_accuracy: 0.0500\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.5882 - accuracy: 0.0400\n",
      "--- Model trained in 3.942950963973999 seconds ---\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3.1825 - accuracy: 0.0600 - val_loss: 3.3727 - val_accuracy: 0.0400\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 3.1045 - accuracy: 0.0700 - val_loss: 3.2344 - val_accuracy: 0.0500\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 3.1165 - accuracy: 0.0700 - val_loss: 3.5189 - val_accuracy: 0.0500\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 3.0950 - accuracy: 0.0700 - val_loss: 3.3333 - val_accuracy: 0.0500\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 3.0689 - accuracy: 0.1000 - val_loss: 3.3639 - val_accuracy: 0.0400\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 3.0604 - accuracy: 0.0700 - val_loss: 3.4287 - val_accuracy: 0.0400\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 3.0543 - accuracy: 0.0700 - val_loss: 3.3477 - val_accuracy: 0.0400\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 3.1977 - accuracy: 0.0700\n",
      "--- Model trained in 3.599529981613159 seconds ---\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 3.1771 - accuracy: 0.0400 - val_loss: 3.2444 - val_accuracy: 0.0100\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 3.1353 - accuracy: 0.0500 - val_loss: 3.2495 - val_accuracy: 0.0100\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 3.1173 - accuracy: 0.0700 - val_loss: 3.2542 - val_accuracy: 0.0500\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 3.1027 - accuracy: 0.0800 - val_loss: 3.2616 - val_accuracy: 0.0500\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 3.0908 - accuracy: 0.0700 - val_loss: 3.2680 - val_accuracy: 0.0400\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 3.0810 - accuracy: 0.1300 - val_loss: 3.2757 - val_accuracy: 0.0400\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3.2104 - accuracy: 0.0700\n",
      "--- Model trained in 1.9667539596557617 seconds ---\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 3.0155 - accuracy: 0.0700 - val_loss: 3.3049 - val_accuracy: 0.0400\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 2.9840 - accuracy: 0.1000 - val_loss: 3.3638 - val_accuracy: 0.0400\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 2.9738 - accuracy: 0.0700 - val_loss: 3.3417 - val_accuracy: 0.0600\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 2.9780 - accuracy: 0.0900 - val_loss: 3.3797 - val_accuracy: 0.0700\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 2.9671 - accuracy: 0.1000 - val_loss: 3.4032 - val_accuracy: 0.0900\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 2.9557 - accuracy: 0.1500 - val_loss: 3.3807 - val_accuracy: 0.0800\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.2706 - accuracy: 0.0400\n",
      "--- Model trained in 1.7355599403381348 seconds ---\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 885ms/step - loss: 3.0212 - accuracy: 0.0900 - val_loss: 3.3810 - val_accuracy: 0.0400\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 3.0163 - accuracy: 0.0900 - val_loss: 3.3705 - val_accuracy: 0.0700\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 3.0133 - accuracy: 0.1100 - val_loss: 3.3945 - val_accuracy: 0.0400\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 3.0112 - accuracy: 0.0900 - val_loss: 3.3781 - val_accuracy: 0.0700\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 3.0086 - accuracy: 0.1100 - val_loss: 3.4009 - val_accuracy: 0.0400\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 3.0062 - accuracy: 0.0900 - val_loss: 3.3831 - val_accuracy: 0.0800\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 3.0047 - accuracy: 0.1100 - val_loss: 3.4098 - val_accuracy: 0.0400\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3.3252 - accuracy: 0.0500\n",
      "--- Model trained in 2.012861967086792 seconds ---\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7537 - accuracy: 0.8200 - val_loss: 3.8537 - val_accuracy: 0.0500\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 2.1875 - accuracy: 0.3300 - val_loss: 3.7321 - val_accuracy: 0.0500\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 1.6092 - accuracy: 0.4800 - val_loss: 3.5337 - val_accuracy: 0.0500\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 1.3172 - accuracy: 0.5700 - val_loss: 3.5210 - val_accuracy: 0.0500\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 1.0207 - accuracy: 0.7400 - val_loss: 3.3858 - val_accuracy: 0.0500\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.7780 - accuracy: 0.8700 - val_loss: 3.3662 - val_accuracy: 0.0500\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.5709 - accuracy: 0.8800 - val_loss: 3.3282 - val_accuracy: 0.0500\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.4947 - accuracy: 0.9200 - val_loss: 3.3083 - val_accuracy: 0.0500\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.4035 - accuracy: 0.9200 - val_loss: 3.2900 - val_accuracy: 0.0500\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 0.3763 - accuracy: 0.9600 - val_loss: 3.2688 - val_accuracy: 0.0500\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.2749 - accuracy: 0.9800 - val_loss: 3.2635 - val_accuracy: 0.0500\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.2541 - accuracy: 0.9800 - val_loss: 3.2458 - val_accuracy: 0.0500\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.1849 - accuracy: 1.0000 - val_loss: 3.2409 - val_accuracy: 0.0500\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.1487 - accuracy: 1.0000 - val_loss: 3.2278 - val_accuracy: 0.0500\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.1290 - accuracy: 1.0000 - val_loss: 3.2268 - val_accuracy: 0.0300\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.1225 - accuracy: 1.0000 - val_loss: 3.2157 - val_accuracy: 0.0300\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.1078 - accuracy: 1.0000 - val_loss: 3.2151 - val_accuracy: 0.0200\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.0896 - accuracy: 1.0000 - val_loss: 3.2077 - val_accuracy: 0.0200\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.0770 - accuracy: 1.0000 - val_loss: 3.2071 - val_accuracy: 0.0100\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 3.2025 - val_accuracy: 0.0100\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 3.2006 - val_accuracy: 0.0300\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 3.1986 - val_accuracy: 0.0400\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 3.1975 - val_accuracy: 0.0500\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 3.1963 - val_accuracy: 0.0500\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.0446 - accuracy: 1.0000 - val_loss: 3.1957 - val_accuracy: 0.0500\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3.1860 - accuracy: 0.0100\n",
      "--- Model trained in 9.012948989868164 seconds ---\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.1165 - accuracy: 0.0700 - val_loss: 3.2414 - val_accuracy: 0.0500\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 3.1104 - accuracy: 0.0700 - val_loss: 3.2492 - val_accuracy: 0.0500\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 3.1042 - accuracy: 0.0700 - val_loss: 3.2580 - val_accuracy: 0.0500\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 3.0979 - accuracy: 0.0700 - val_loss: 3.2679 - val_accuracy: 0.0500\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 3.0920 - accuracy: 0.0700 - val_loss: 3.2789 - val_accuracy: 0.0500\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 3.0865 - accuracy: 0.0700 - val_loss: 3.2906 - val_accuracy: 0.0500\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.2014 - accuracy: 0.0700\n",
      "--- Model trained in 2.971065044403076 seconds ---\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Unknown optimizer: rsmprop. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-62fe8624f921>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Compile model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Define the callbacks and save the best model to a new file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_eagerly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_eagerly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m       self.compiled_loss = compile_utils.LossesContainer(\n\u001b[1;32m    575\u001b[0m           loss, loss_weights, output_names=self.output_names)\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_get_optimizer\u001b[0;34m(self, optimizer)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_single_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 867\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_get_single_optimizer\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_single_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m       \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m       if (loss_scale is not None and\n\u001b[1;32m    604\u001b[0m           not isinstance(opt, lso.LossScaleOptimizer)):\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'config'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     raise ValueError(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     92\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m   return deserialize_keras_object(\n\u001b[0m\u001b[1;32m     95\u001b[0m       \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[0;31m# In this case we are dealing with a Keras config dictionary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[0m\u001b[1;32m    654\u001b[0m         config, module_objects, custom_objects, printable_module_name)\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    554\u001b[0m   \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_registered_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;34m'Unknown {}: {}. Please ensure this object is '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;34m'passed to the `custom_objects` argument. See '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown optimizer: rsmprop. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "for optimizer in optimizers:\n",
    "    for model in models:\n",
    "        # Time the time it takes to train the model\n",
    "        start = time.time()\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Define the callbacks and save the best model to a new file\n",
    "        callbacks = [keras.callbacks.ModelCheckpoint(filepath=f'models/{model.name}.keras', save_best_only=True, monitor='val_loss'), \n",
    "            keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta = 0.01, patience = 5, verbose = 1, restore_best_weights = True)]\n",
    "        # Train model\n",
    "        model.fit(fft_dataset_train, labels_train, epochs=30, batch_size = 256, validation_data = (fft_dataset_val, labels_val), callbacks=callbacks)\n",
    "\n",
    "        # Evaluate model\n",
    "        _, accuracy = model.evaluate(fft_dataset_test, labels_test)\n",
    "\n",
    "        print(\"--- Model trained in %s seconds ---\" % (time.time() - start))\n",
    "\n",
    "        # Write accuracy to file\n",
    "        f = open(\"models/accuracy_log.txt\", \"a\")\n",
    "        f.write(f\"Model {model.name} evaluated an accuracy of {accuracy}.\\n\")\n",
    "        f.write(f\"Model {model.name} trained in {int(time.time() - start)} seconds.\\n\\n\")\n",
    "        f.close()"
   ]
  }
 ]
}
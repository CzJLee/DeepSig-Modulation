{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd07e85ec9bf098c5427e45e2f632dcd4eeff803b007e1abd287d600879388709c1",
   "display_name": "Python 3.8.10 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "7e85ec9bf098c5427e45e2f632dcd4eeff803b007e1abd287d600879388709c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import signal_processing as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sys import getsizeof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datasets\n",
    "dataset_directory = os.path.join(os.getcwd(), \"DeepSig-Dataset-2018\")\n",
    "\n",
    "# Use these to load the entire dataset into memory\n",
    "fft_dataset_train = np.load(os.path.join(dataset_directory, \"fft_dataset_train.npy\"))\n",
    "fft_dataset_val = np.load(os.path.join(dataset_directory, \"fft_dataset_val.npy\"))\n",
    "fft_dataset_test = np.load(os.path.join(dataset_directory, \"fft_dataset_test.npy\"))\n",
    "\n",
    "labels_train = np.load(os.path.join(dataset_directory, \"labels_train.npy\"))\n",
    "labels_val = np.load(os.path.join(dataset_directory, \"labels_val.npy\"))\n",
    "labels_test = np.load(os.path.join(dataset_directory, \"labels_test.npy\"))\n",
    "\n",
    "# # Use these to use a memory map to save RAM\n",
    "# fft_dataset_train = np.load(os.path.join(dataset_directory, \"fft_dataset_train.npy\"), mmap_mode=\"r+\")\n",
    "# fft_dataset_val = np.load(os.path.join(dataset_directory, \"fft_dataset_val.npy\"), mmap_mode=\"r+\")\n",
    "# fft_dataset_test = np.load(os.path.join(dataset_directory, \"fft_dataset_test.npy\"), mmap_mode=\"r+\")\n",
    "\n",
    "# labels_train = np.load(os.path.join(dataset_directory, \"labels_train.npy\"), mmap_mode=\"r+\")\n",
    "# labels_val = np.load(os.path.join(dataset_directory, \"labels_val.npy\"), mmap_mode=\"r+\")\n",
    "# labels_test = np.load(os.path.join(dataset_directory, \"labels_test.npy\"), mmap_mode=\"r+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model constructor\n",
    "def model_constructor():\n",
    "    inputs = keras.Input(shape=(1024, 1))\n",
    "    x = layers.Conv1D(filters=16, kernel_size=3, activation='relu')(inputs)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=32, kernel_size=3, activation='relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    outputs = layers.Dense(24, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Define the callbacks and save the best model to a new file\n",
    "    callbacks = [keras.callbacks.ModelCheckpoint(filepath='models/cnn_test.keras', save_best_only=True, monitor='val_loss'), \n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta = 0.01, patience = 5, verbose = 1, restore_best_weights = True)]\n",
    "\n",
    "    return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_4 (InputLayer)         [(None, 1024, 1)]         0         \n_________________________________________________________________\nconv1d_20 (Conv1D)           (None, 1022, 16)          64        \n_________________________________________________________________\nmax_pooling1d_17 (MaxPooling (None, 511, 16)           0         \n_________________________________________________________________\nconv1d_21 (Conv1D)           (None, 509, 32)           1568      \n_________________________________________________________________\nmax_pooling1d_18 (MaxPooling (None, 254, 32)           0         \n_________________________________________________________________\nconv1d_22 (Conv1D)           (None, 252, 64)           6208      \n_________________________________________________________________\nmax_pooling1d_19 (MaxPooling (None, 126, 64)           0         \n_________________________________________________________________\nconv1d_23 (Conv1D)           (None, 124, 128)          24704     \n_________________________________________________________________\nmax_pooling1d_20 (MaxPooling (None, 62, 128)           0         \n_________________________________________________________________\nconv1d_24 (Conv1D)           (None, 60, 256)           98560     \n_________________________________________________________________\nmax_pooling1d_21 (MaxPooling (None, 30, 256)           0         \n_________________________________________________________________\nconv1d_25 (Conv1D)           (None, 28, 256)           196864    \n_________________________________________________________________\nmax_pooling1d_22 (MaxPooling (None, 14, 256)           0         \n_________________________________________________________________\nconv1d_26 (Conv1D)           (None, 12, 256)           196864    \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 3072)              0         \n_________________________________________________________________\ndense_9 (Dense)              (None, 256)               786688    \n_________________________________________________________________\ndense_10 (Dense)             (None, 128)               32896     \n_________________________________________________________________\ndense_11 (Dense)             (None, 24)                3096      \n=================================================================\nTotal params: 1,347,512\nTrainable params: 1,347,512\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, callbacks = model_constructor()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time the time it takes to train the model\n",
    "start = time.time()\n",
    "\n",
    "history = model.fit(fft_dataset_shuffled, labels_shuffled, epochs=30, batch_size = 256, validation_split = 0.3, callbacks=callbacks)\n",
    "\n",
    "print(\"--- Model trained in %s seconds ---\" % (time.time() - start))"
   ]
  }
 ]
}